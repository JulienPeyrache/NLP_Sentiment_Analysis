{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" cellpadding=\"5\" cellspacing=\"0\" width=\"100%\">\n",
    "   <tr>\n",
    "      <!--<td align=\"left\" valign=\"top\" width=\"120\"><img src=\"./pictures/octopeek-logo.png\" width=\"120\" /></td>-->\n",
    "      <td align=\"left\" valign=\"top\" width=\"120\"><img src=\"https://media-exp1.licdn.com/dms/image/C510BAQE93sqc09g7qg/company-logo_200_200/0?e=2159024400&v=beta&t=Ebcbl-_mVoiGn-jo8xRX3V0iuAckEhZXnLKcmnOv2Wk\" width=\"120\" /></td>\n",
    "      <td valign=\"top\" width=\"100%\" align=\"center\"><h1><font color=\"blue\">Enseignement d'Intégration - Sujet Octopeek</font></h1>\n",
    "      <p align=\"right\"><h2>Analyse de sentiments sur des Tweets</h2></p>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données d'entrainement\n",
    "\n",
    "Ce notebook est destiné à la préparation des données d'entrainement. Les données vous permettront d'entrainer un modèle de prédiction de sentiment dans le texte. Ce travail est indépendant des données de votre projet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération de données d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trouvez sur internet des jeux de données (au minium 2) en langue anglaise pouvant permettre d'entrainer un modèle de prédiction de polarité. Chaque ligne du jeu de données doit avoir au minimum un texte brut ainsi qu'un label de polarité. Le jeu de données ne doit pas forcement être composé de tweets. A noter cependant que votre modèle final sera évalué sur des données de type tweets.\n",
    "\n",
    "Conservez la source de ces données (le lien vers les données et l'article scientifique s'il existe). Vous devez présenter (dans votre rapport et durant la présentation) les données, et les avantages / désavantages :\n",
    "\n",
    " 1. des labels de ces données ;\n",
    " 2. de la fiabilité de leur collecte ou de leur détermination (par ceux qui ont construit le jeu de données) ;\n",
    " 3. des données en elles-mêmes vis-à-vis de vos besoins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.2.4-cp38-cp38-manylinux1_x86_64.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.20.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 15.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2021.4.4-cp38-cp38-manylinux2014_x86_64.whl (733 kB)\n",
      "\u001b[K     |████████████████████████████████| 733 kB 30.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.56.0)\n",
      "Collecting click\n",
      "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 3.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: regex, joblib, click, nltk\n",
      "Successfully installed click-8.0.1 joblib-1.0.1 nltk-3.6.2 regex-2021.4.4\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.20.0)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mres_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-381772c148ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' pip install sklearn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;31m# Ensure new system_piped implementation is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;31m# Ensure the subprocess really is terminated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;31m# add isalive check, to ensure exitstatus is set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGHUP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterterminate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'sentiment'], dtype='object')\n",
      "50000\n",
      "A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/jovyan/IMDB_Dataset.csv\")\n",
    "print(df.columns)\n",
    "df['review']\n",
    "print(len(df))\n",
    "print(df['review'][1])\n",
    "\n",
    "#mise des données dans un dictionnaire\n",
    "\n",
    "dico = {}\n",
    "for i in range(len(df)-1):\n",
    "    if df['sentiment'][i]=='positive':\n",
    "        dico[df['review'][i]] =  1\n",
    "    else:\n",
    "        dico[df['review'][i]] =  -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Vous devez choisir un jeu de données qui permettra à votre modèle de bien généraliser et bien s’entraîner. Vous pouvez en choisir plusieurs et les fusionner. Justifiez vos choix dans le rapport. Ici l'important c'est de réussir le challenge, quitte à être un peu moins précis sur le \"domaine\" de vos données projet.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Vérifiez bien que votre jeu de donnée comporte la classe \"neutral\" (regardez bien en parcourant les données car certains jeux de données prévoient cette classe mais n'ont aucun tweet de cette classe). Dans vos données projet, la plupart des tweets ne correspondront à aucun sentiment, ils seront neutres. Le problème est que votre modèle entraîné avec ce type de jeu de données ne pourra pas vous prédire les tweets neutres, il donnera toujours soit positif soit négatif. Il y a 2 solutions à cela : soit vous utilisez un autre jeu de données, soit vous introduisez des tweets aléatoirement qui ne viennent pas d'un jeu de données de sentiment et vous les considérez neutres. Cette solution peut biaiser l'apprentissage, mais vous profitez de plus de données. Attention à être cohérent en terme de nombre d'echantillons (avoir un nombre de tweets neutres du même ordre de grandeur). Nous pouvons vous fournir des tweets aléatoires si vous le demandez.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des données brutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegardez le jeu de données en fichier serialisé \"pickle\". Le format doit correspondre à notre format, i.e. une liste de dictionnaires ayant au minimum les champs `text` et `polarity`. Si les données sont des *tweets*, vous devez ajouter le champs `id`. Exemple `[{'text': 'Raw text of the first sample.', 'polarity': 'neutral'}, {'text': 'Raw text of the second sample.', 'polarity': 'positive'}, ...]`.\n",
    "\n",
    "Vous nommerez le fichier `group<X>_<dataname>_rawdata.pickle` avec `X` le numéro de votre groupe et `dataname` le nom du dataset en enlevant les chevrons. Si le jeu de données n'a pas de nom, vous pouvez en inventer un qui reflète la source (e.g. le site web, l'article source) ou le \"domaine\" des données (i.e. le topic, le type de données texte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\", 'polarity': 1}, {'text': 'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.', 'polarity': 1}, {'text': 'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.', 'polarity': 1}]\n"
     ]
    }
   ],
   "source": [
    "# Conversion en liste de dictionnaires :\n",
    "\n",
    "l = []\n",
    "for n in dico:\n",
    "    dico1 = {}\n",
    "    dico1['text'] = n\n",
    "    dico1['polarity'] = dico[n]\n",
    "    l.append(dico1)\n",
    "    \n",
    "print(l[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialisation pickle :\n",
    "\n",
    "# Sauvegarde des données en .pickle:\n",
    "import pickle\n",
    "with open('group12_trainingex.pickle', 'wb') as f:\n",
    "  group12_trainingex = pickle.dump(l, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Lorsque vous ne connaissez pas un outil ou une notion, le premier réflèxe que vous devez avoir est de <b>comprendre</b> et <b>trouver des exemples</b>. Pour la sauvegarde pickle, vous chercherez par exemple \"pickle\" sur un moteur de recherche et vous trouverez la <a href=\"https://docs.python.org/3/library/pickle.html\">documentation</a> ou des <a href=\"https://yasoob.me/2013/08/02/what-is-pickle-in-python\">articles expliquant son utilisation</a>. Lorsqu'il s'agit de traitements basiques comme pour la sauvegarde pickle, vous chercherez des exemples à copier en tapant par exemple \"How to pickle a list?\", vous trouverez alors des <a href=\"https://stackoverflow.com/questions/25464295/how-to-pickle-a-list/25465148\">solutions</a>, souvent sur le site *StackOverflow*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement du texte brut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devez prétraiter les données textuelles en éliminant les liens, les accents et les caractères spéciaux. Vous devez conserver les émoticônes, les hashtags et les mentions @. Les labels doivent prendre les valeurs `-1` pour négatif, `0` pour neutre et `1` pour positif. Si l'échelle est pus grande, appliquez des seuils en justifiant vos choix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unicode in /opt/conda/lib/python3.8/site-packages (2.8)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on retire les accents, les caractères spéciaux, les liens hypertextes\n",
    "import unicodedata, re\n",
    "\n",
    "\n",
    "def retirer_liens(s) :\n",
    "  return re.sub(r\"http\\S+\", \"\", s)\n",
    "\n",
    "def retirer_caracteres_speciaux(s) :\n",
    "  caracteres_speciaux ='~!$%^&*()_-+={}\\/:;<>?.'\n",
    "  for i in caracteres_speciaux :\n",
    "     s = s.replace(i, ' ')\n",
    "  return s\n",
    "\n",
    "\n",
    "\n",
    "def retirer_break(s):\n",
    "    \n",
    "    return s.replace(\"<br /><br />\", \" \")\n",
    "\n",
    "\n",
    "def retirer_accents(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Vous aurez besoin de ces fonctions pour la suite du projet, nous vous conseillons de les exportées dans un fichier nommé <strong>utils.py</strong>. Puis importez le module dans la cellcule au dessus. Vous placerez toutes les fonctions communes aux différents notebook dans ce fichier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked  They are right, as this is exactly what happened with me  br    br   The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO  Trust me, this is not a show for the faint hearted or timid  This show pulls no punches with regards to drugs, sex or violence  Its is hardcore, in the classic use of the word  br    br   It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary  It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda  Em City is home to many  Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more    so scuffles, death stares, dodgy dealings and shady agreements are never far away  br    br   I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare  Forget pretty pictures painted for mainstream audiences, forget charm, forget romance   OZ doesn't mess around  The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence  Not just violence, but injustice  crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience  Watching Oz, you may become comfortable with what is uncomfortable viewing    thats if you can get in touch with your darker side \", 'polarity': 1}, {'text': 'A wonderful little production   br    br   The filming technique is very unassuming  very old time BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece   br    br   The actors are extremely well chosen  Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too  You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece  A masterful production about one of the great master\\'s of comedy and his life   br    br   The realism really comes home with the little things  the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears  It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets  particularly of their flat with Halliwell\\'s murals decorating every surface  are terribly well done ', 'polarity': 1}, {'text': 'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light hearted comedy  The plot is simplistic, but the dialogue is witty and the characters are likable  even the well bread suspected serial killer   While some may be disappointed when they realize this is not Match Point 2  Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love  br    br   This was the most I\\'d laughed at one of Woody\\'s comedies in years  dare I say a decade    While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman  br    br   This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends ', 'polarity': 1}]\n"
     ]
    }
   ],
   "source": [
    "# Prétraitement de chaque champs `text` du jeu de données :\n",
    "\n",
    "for i in range(len(l)-1) : \n",
    "    l[i]['text'] = retirer_liens(l[i]['text'])\n",
    "    l[i]['text'] = retirer_caracteres_speciaux(l[i]['text'])\n",
    "    l[i]['text'] = retirer_break(l[i]['text'])  \n",
    "    l[i]['text'] = retirer_accents(l[i]['text'])\n",
    "print(l[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la fonction de conversion des labels :\n",
    "def article_tokenize_simple(text):\n",
    "        tokens=text.split()  \n",
    "        return tokens       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'doc_id': 0, 'tokens': ['One', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'Oz', 'episode', \"you'll\", 'be', 'hooked', 'They', 'are', 'right,', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'br', 'br', 'The', 'first', 'thing', 'that', 'struck', 'me', 'about', 'Oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence,', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'GO', 'Trust', 'me,', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', 'This', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs,', 'sex', 'or', 'violence', 'Its', 'is', 'hardcore,', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'br', 'br', 'It', 'is', 'called', 'OZ', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'Oswald', 'Maximum', 'Security', 'State', 'Penitentary', 'It', 'focuses', 'mainly', 'on', 'Emerald', 'City,', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards,', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'Em', 'City', 'is', 'home', 'to', 'many', 'Aryans,', 'Muslims,', 'gangstas,', 'Latinos,', 'Christians,', 'Italians,', 'Irish', 'and', 'more', 'so', 'scuffles,', 'death', 'stares,', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'br', 'br', 'I', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', \"wouldn't\", 'dare', 'Forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences,', 'forget', 'charm,', 'forget', 'romance', 'OZ', \"doesn't\", 'mess', 'around', 'The', 'first', 'episode', 'I', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal,', 'I', \"couldn't\", 'say', 'I', 'was', 'ready', 'for', 'it,', 'but', 'as', 'I', 'watched', 'more,', 'I', 'developed', 'a', 'taste', 'for', 'Oz,', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'Not', 'just', 'violence,', 'but', 'injustice', 'crooked', 'guards', \"who'll\", 'be', 'sold', 'out', 'for', 'a', 'nickel,', 'inmates', \"who'll\", 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it,', 'well', 'mannered,', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'Watching', 'Oz,', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side'], 'polarity': 1}, {'doc_id': 1, 'tokens': ['A', 'wonderful', 'little', 'production', 'br', 'br', 'The', 'filming', 'technique', 'is', 'very', 'unassuming', 'very', 'old', 'time', 'BBC', 'fashion', 'and', 'gives', 'a', 'comforting,', 'and', 'sometimes', 'discomforting,', 'sense', 'of', 'realism', 'to', 'the', 'entire', 'piece', 'br', 'br', 'The', 'actors', 'are', 'extremely', 'well', 'chosen', 'Michael', 'Sheen', 'not', 'only', '\"has', 'got', 'all', 'the', 'polari\"', 'but', 'he', 'has', 'all', 'the', 'voices', 'down', 'pat', 'too', 'You', 'can', 'truly', 'see', 'the', 'seamless', 'editing', 'guided', 'by', 'the', 'references', 'to', \"Williams'\", 'diary', 'entries,', 'not', 'only', 'is', 'it', 'well', 'worth', 'the', 'watching', 'but', 'it', 'is', 'a', 'terrificly', 'written', 'and', 'performed', 'piece', 'A', 'masterful', 'production', 'about', 'one', 'of', 'the', 'great', \"master's\", 'of', 'comedy', 'and', 'his', 'life', 'br', 'br', 'The', 'realism', 'really', 'comes', 'home', 'with', 'the', 'little', 'things', 'the', 'fantasy', 'of', 'the', 'guard', 'which,', 'rather', 'than', 'use', 'the', 'traditional', \"'dream'\", 'techniques', 'remains', 'solid', 'then', 'disappears', 'It', 'plays', 'on', 'our', 'knowledge', 'and', 'our', 'senses,', 'particularly', 'with', 'the', 'scenes', 'concerning', 'Orton', 'and', 'Halliwell', 'and', 'the', 'sets', 'particularly', 'of', 'their', 'flat', 'with', \"Halliwell's\", 'murals', 'decorating', 'every', 'surface', 'are', 'terribly', 'well', 'done'], 'polarity': 1}, {'doc_id': 2, 'tokens': ['I', 'thought', 'this', 'was', 'a', 'wonderful', 'way', 'to', 'spend', 'time', 'on', 'a', 'too', 'hot', 'summer', 'weekend,', 'sitting', 'in', 'the', 'air', 'conditioned', 'theater', 'and', 'watching', 'a', 'light', 'hearted', 'comedy', 'The', 'plot', 'is', 'simplistic,', 'but', 'the', 'dialogue', 'is', 'witty', 'and', 'the', 'characters', 'are', 'likable', 'even', 'the', 'well', 'bread', 'suspected', 'serial', 'killer', 'While', 'some', 'may', 'be', 'disappointed', 'when', 'they', 'realize', 'this', 'is', 'not', 'Match', 'Point', '2', 'Risk', 'Addiction,', 'I', 'thought', 'it', 'was', 'proof', 'that', 'Woody', 'Allen', 'is', 'still', 'fully', 'in', 'control', 'of', 'the', 'style', 'many', 'of', 'us', 'have', 'grown', 'to', 'love', 'br', 'br', 'This', 'was', 'the', 'most', \"I'd\", 'laughed', 'at', 'one', 'of', \"Woody's\", 'comedies', 'in', 'years', 'dare', 'I', 'say', 'a', 'decade', 'While', \"I've\", 'never', 'been', 'impressed', 'with', 'Scarlet', 'Johanson,', 'in', 'this', 'she', 'managed', 'to', 'tone', 'down', 'her', '\"sexy\"', 'image', 'and', 'jumped', 'right', 'into', 'a', 'average,', 'but', 'spirited', 'young', 'woman', 'br', 'br', 'This', 'may', 'not', 'be', 'the', 'crown', 'jewel', 'of', 'his', 'career,', 'but', 'it', 'was', 'wittier', 'than', '\"Devil', 'Wears', 'Prada\"', 'and', 'more', 'interesting', 'than', '\"Superman\"', 'a', 'great', 'comedy', 'to', 'go', 'see', 'with', 'friends'], 'polarity': 1}]\n"
     ]
    }
   ],
   "source": [
    "# Conversion de tous les labels :\n",
    "\n",
    "\n",
    "tokenized_collection=[]\n",
    "for i in range(len(l)-1):\n",
    "    t = l[i]['text']\n",
    "    t=retirer_accents(t)\n",
    "    t=retirer_liens(t)\n",
    "    t=retirer_break(t)\n",
    "    t= retirer_caracteres_speciaux(t)\n",
    "    t=article_tokenize_simple(t)\n",
    "    d={}\n",
    "    d['doc_id']=i\n",
    "    d['tokens']= t\n",
    "    d['polarity']=l[i]['polarity']\n",
    "    tokenized_collection.append(d)\n",
    "\n",
    "\n",
    "print(tokenized_collection[0:3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Lorsque vous prétraitez le jeu de données, évitez d'effectuer les étapes de <strong>tokenization</strong> et de <strong>lemmatization</strong> qui vont trop dénaturer les données brutes, ceci afin d'éviter de ne trop contraindre l'utilisation des modèles que vous pourrez utiliser.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des données prétraitées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegardez les données prétraitées selon le même format (liste de dicts pickle) en nommant le fichier `group<X>_<dataname>_preprocessed.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des données en fichier .pickle :\n",
    "\n",
    "\n",
    "import pickle\n",
    "file_Name = \"group12_IMBD_preprocessed.pickle\"\n",
    "# open the file for writing\n",
    "fileObject = open(file_Name,'wb')\n",
    "\n",
    "pickle.dump(l,fileObject) \n",
    "\n",
    "fileObject.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statitiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie est libre. Vous proposerez un aperçu de votre jeu de données pour votre rapport et présentation. Vous pourez par exemple donner le nombre d'exemples dans votre jeu de données, la taille moyenne des textes, la proportion de chaque label. Vous proposerez un visuel, par exemple un nuage de mots en utilisant un model de topic modeling (NMF ou LDA), en utilisant [WordCloud](https://github.com/amueller/word_cloud) (vous trouverez des exemples) ou encore en utilisant la pondération TFIDF en intégrant d'autres tweets externes. Ces méthodes vous permettent d'éviter d'afficher des mots communs tels que \"day\", \"shall\", \"section\" que vous n'aurez pas supprimés via une liste de *stop words*. Vous pouvez trouver d'autres visuels tels qu'un histogramme des émoticônes en fonction de la polarité ou tout autre graphe original..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d exemples :  49581 \n",
      " Longueur moyenne des tweets :  1310.4721970109622 \n",
      " Ratio de tweets positifs :  0.5018858030293862 \n",
      " Ratio de tweets negatifs :  0.49811419697061377\n"
     ]
    }
   ],
   "source": [
    "# Présentation de quelques chiffres :\n",
    "\n",
    "nombre_echantillons = len(l)\n",
    "pos,neg,longueur_moyenne_tweets = 0,0,0\n",
    "for dico in l:\n",
    "    pos+=max(0,dico['polarity'])\n",
    "    neg-=min(0,dico['polarity'])\n",
    "    longueur_moyenne_tweets+=len(dico['text'])/len(l)\n",
    "ratio_positif = pos/nombre_echantillons\n",
    "ratio_negatif = neg/nombre_echantillons\n",
    "print('Total d exemples : ',nombre_echantillons,'\\n', 'Longueur moyenne des tweets : ', longueur_moyenne_tweets, '\\n', 'Ratio de tweets positifs : ', ratio_positif,'\\n', 'Ratio de tweets negatifs : ', ratio_negatif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.8/site-packages (1.8.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from wordcloud) (3.3.4)\r\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.8/site-packages (from wordcloud) (1.20.0)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from wordcloud) (8.1.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de, au moins, un graphique :\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "def texte_total_concatene(l):\n",
    "    s=''\n",
    "    for dico in l :\n",
    "          s+= dico['text']\n",
    "    return s\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(WordCloud().generate(texte_total_concatene(l)), interpolation=\"bilinear\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Pour la partie graphique, vous pouvez utiliser <a href=\"https://docs.bokeh.org/en/latest/index.html\">Bokeh</a> ou <a href=\"https://matplotlib.org/\">Matplotlib</a>. Encore une fois, n'hésitez pas à reprendre des exemples sur internet.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
